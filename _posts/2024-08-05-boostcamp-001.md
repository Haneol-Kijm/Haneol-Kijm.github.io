---
title: 부캠 1주차 일일 후기
layout: post
description: 1주차 후기
draft: true
---

# 부캠 1주차

## 1일차:

### 오리엔테이션

### 부캠 강의

- pytorch 텐서와 데이터 형태 및 타입 캐스팅에 대해 학습함
- 텐서를 생성하고 cpu, cuda로 만드는 법을 배움
- [detach와 clone의 차이](https://hongl.tistory.com/363)에 대해 따로 공부함

### 피어 세션

자기소개 나누고, 그라운드룰을 정하고, mlops를 같이 해보는 것이 어떻냐는 제안으로 마무리 함

### 후기

- 앞으로 매일 개인 공부-논문 1개 정독이나 그에 준하는 내용(블로그, 강의 자료)을 공부할 것으로 다짐함
- 첫날이라 얼타기도 하고 프로그램에 아직 적응이 안되기는 하는데, 내일부터는 수업시청-개인 공부-단체 프로젝트의 3박자를 갖추어 나가면 좋겠다고 생각함

## 2일차

### 부캠 강의

- reshape와 view, continguous에 대해 헷갈리고 잘 모르고 있었는데 메모리 공간에서의 차이와 reshape가 새로운 메모리를 할당한다는 점, 따라서 view가 더 효율적이란 점을 새로 배워 개념 정리가 깔끔하게 되었다.
- stack은 반드시 차원이 늘어난다는 점을 깨달았다(numpy의 vstack, hstack과 다르다)
늘리지 않고 붙이려면 **torch.cat(concatenation)**
- expand는 메모리를 온존하고 repeat는 메모리를 복사해서 새로 생성하는 차이점을 익혔다.
- 과제 제출이 생각보다 오래 걸렸으며, 다양한 관점에서 텐서를 써볼 수 있어서 좋았다. 기반을 탄탄히 한 느낌

### 개인 학습

진행하지 못함

### 피어 세션

- 캠퍼님의 깃허브로부터 유용한 [노션-깃허브 연동형 후기 남기는 방법](https://jekyllrb-ko.github.io/)을 발견하여 크게 도움이 되었다. 이 학습정리에도 적용하려고 한다.
- 논문 리딩을 하고 싶었는데 미처 과제로 인해 못한 점이 아쉽다. 내일은 jekyll 적용 작업을 끝내거나, 논문 리딩을 한 편 꼭 하거나 둘 중 하나 만큼은 하고 싶으며, 가급적 오후 4시 전에 진행하고 싶다.

## 3일차:

### 피어세션이 피어씁니다

### 부캠 강의

- 답이 정해져있는 선형회귀를 pytorch 코드 구현 관점에서 바라볼 수 있다는 점이 신선했다.
- normalization을 하고 안하고의 차이가 다시금 학습에 큰 영향을 줌을 깨달았다. 데이터의 관계성은 당연히 스케일 조정을 해줘야하는 것이다.

### 개인 학습: [Introduction to LLM genAI](https://www.assemblyai.com/blog/introduction-large-language-models-generative-ai/)

- LLM을 아주 쉽게 설명하고 있어서 다른 캠퍼에게도 추천할 만 한 것 같다.
- 특히 self-supervised 개념을 아주 간단히 소개해서 직관적이었다.
- 추가로 이어서 읽어볼 만한 블로그 글(큰 파라미터 갯수로 나타난 conditioned 기능들):
    - [5400억 파라미터 사이즈로 나타난 돌파 성능](https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-for-breakthrough-performance/?ref=changelog.assemblyai.com)
    - [LLM에 새롭게 드러나는 기능들](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/)
- ChatGPT는 이에 더해 기억 능력(휴먼 피드백)을 가지고 있는데, 이는 위의 LLM을 부가적 보상 모델로 쓰고, 강화 학습 개념을 추가하여 사용자의 기대를 충족할만한 답변들에 점수를 매긴다고 한다.
    - 이에 대해 추가로 읽어볼 게시글: [how-chatgpt-actually-works](https://www.assemblyai.com/blog/how-chatgpt-actually-works/)
    - 추가로 이어지는 오디오 생성 관련 주제: [recent-developments-in-generative-ai-for-audio](https://www.assemblyai.com/blog/recent-developments-in-generative-ai-for-audio/)

피어 세션:

- 서로에 대해 좀 더 친숙하게 떠드는 시간을 가졌고, 좋은 시간이 되었다
- 앞으로의 피어 세션에서 확실하게 무엇을 할 지 정하는 시간도 가졌고, 부담없이 피어세션에 참가할 수 있게 되어 기쁘다
- 목요일에는 github 스터디, 금요일에는 심화과제 스터디를 하기로 결정했다.

## 4일차:

부캠 강의:

- 로지스틱 회귀를 sigmoid를 활성함수로 쓰는 MLP로 생각할 수 있다는 점을 깨달았다
- 바이너리 크로스 엔트로피를 직접 유도하여 의미를 깨달아봐야 확률통계와 좀 더 친해질 수 있다

개인학습: github를 jekyll 블로그로 바꾸는 과정을 작업하였으나 아직 보완해야할 부분이 많다.

- 블로그 글 숨기기
- github 아이콘 추가하기
- 프로젝트 설명 추가하기
- 자기소개 자세하게 쓰기 등…

피어 세션: github 버전관리 pull request 연습을 진행했는데 생각보다 동시에 진행하니 어려운 점이 많았다. 조심해서 해야할 듯.

마스터클래스

## 5일차:

부캠 강의: 과제 제출 및 퀴즈를 완료하였다.

개인 학습:

- [AI trends 2024-Graph Neural Network](https://www.assemblyai.com/blog/ai-trends-graph-neural-networks/)
에서는 제약, 교통시간예측, 추천 시스템, 단백질 합성 등 다양한 분야에 적용되는 GNN의 면모들을 소개하고 있으나, 구체적으로 어떤 원리로 작동하는지는 소개하고 있지 않다.
- [Introduction to Node Embedding](https://memgraph.com/blog/introduction-to-node-embedding?ref=assemblyai.com)
위 글에서 인용되었던 이 글에서는 노드 임베딩 개념을 소개하며, 임베딩을 통해 지도 학습보다 더 좋은 성능을 낼 수 있다고 주장한다. 다만 원하던 GNN 관련 내용은 아니었으며, 간단한 개념 소개 정도의 글로 보여진다. 따라서 GNN 소개 글을 직접 찾아보았다.
- [GNN 소개-기초부터 논문까지](https://medium.com/watcha/gnn-%EC%86%8C%EA%B0%9C-%EA%B8%B0%EC%B4%88%EB%B6%80%ED%84%B0-%EB%85%BC%EB%AC%B8%EA%B9%8C%EC%A7%80-96567b783479)
구글에서 찾은 간결하고 번역된 소개글이다. GNN의 3가지 종류를 소개하고 있으며, 노드 임베딩이 할 수 있는 3가지 결과가 GNN이 할 수 있는 사용처와 거의 겹쳐서 놀랐다.
노드 임베딩이 GNN의 아웃풋으로 쓰이기 때문에 이렇게 되는 것이다. 이 글에서 소개하는 사용처는 노드 분류, 링크 예측, 그래프 분류가 있다.
    - 이 글에서 소개한 recursive gnn을 알고 싶다면 [해당 논문](https://ieeexplore.ieee.org/document/4700287) 을 읽어야할 것이고
    - graph cnn이자 AI trend in 2024에서 소개한 [GraphSage](https://arxiv.org/abs/1706.02216?ref=assemblyai.com)를 알고 싶다면 원본 논문을 읽는 편이 좋아보인다. 당장은 옛날 논문보단 최신 트렌드에 관심이 있으므로 후자를 읽고 싶다.

피어 세션:

- 팀 회고 시간을 가지던 과정에서 유용한 코랩 단축키(alt+shft+L)을 알게 되었다. 매주 금요일 회고 시간을 가지기로 했다.

## 1주차 후기:

- 좋았던 점: 늦게 자고 늦게 일어나던 생활 습관을 고쳤으며,
학습 시간에 집중력이 생기고 이것저것 찾아보며 공부하는 대학원 시절 습관을 회복하고 있다.
- 아쉬운 점: 취업 관련 활동을 전혀 하지 않았다.
다음주부턴 블로그를 다듬으면서 이력서, 포트폴리오를 같이 다듬을 것
- 도전할 점: Github 블로그를 만든 이상 블로그를 본격적으로 꾸미고 싶다.
- 알게된 점:
    - LLM의 작동 원리를 이해했으며, 비지도 학습이 간단한 언어 분야와 달리, 다른 분야에서는 어떤 식으로 비지도학습을 하는지 궁금하다.
    - 다양한 GNN 종류를 이해했으며, 최근에는 어떤 모델이 쓰이는지 궁금하다.
