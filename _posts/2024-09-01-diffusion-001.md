---
title: Diffusion 공부 정리 1회차
layout: post
use_math: true
---

이 글은 제가 네이버 부스트캠프 활동 중에 작성한 후기글에 있는 Diffusion 공부 요약본들을 모아서 다시 작성한 요약 모음집입니다. 1회차 공부이기 때문에 개념 정리가 그리 깔끔하게 되어있지는 않으며, 피상적인 내용 요약에만 집중한 감이 없지 않아 있습니다. 중간중간 제대로 이해하지 못한 부분이나 설명이 부족한 부분이 있을 수 있기 때문에, 내용 정리로 보는 것은 추천드리지 않습니다. 단지 제 자신의 학습 기록을 위해 남기는 것이니 이 점 참고해주시면 좋겠습니다. 

이 공부를 위해 [다음과 같은 수업 ppt](https://ernestryu.com/courses/FM.html)에서 Ch.0~Ch5를 참고해서 공부했습니다. 추가로 뒤에 남아있는 NLP, LLM, VLM 관련 내용도 시간이 되면 확인해보고 싶습니다.

또한 2회차 Diffusion 공부도 시간이 된다면 [다른 자료](https://arxiv.org/abs/2208.11970)를 통해서라도 진행하고 싶습니다.

## Diffusion chapter 0:

### Neural ODE

- Residual neural net의 층을 time index로 연속적으로 보면 상미분 방정식으로 해석할 수 있다는 게 놀라울 따름. 또한 비슷하게 chain rule을 써서 backprop의 해를 항상 구할 수 있다는 것이 보장됨
- 이를 뉴럴 네트워크로 해석하려면 gradient의 계산이 필요한데, input에 대한 미분값은 구할 수 있으나 parameter에 대한 미분값을 구하기가 어려움. 따라서 parameter도 시간에 따라 변하는 것으로 조작하여 문제를 해결함. Neural ODE는 이에 따라, ODE solver를 2번 호출하는 것으로 항상 계산할 수 있음

### FFJORD

- Flow model이란 IID Gaussian 분포를 어떤 invertible한 함수를 통해 보낸 값으로 데이터를 샘플링하고 생성하는 생성형 모델임.
- Flow model에 위의 Neural ODE를 결합하여, FFJORD(Free-Form Jacobian Of Reversible Dynamics) 모델을 만들 수 있음. 이 모델은 가우시안 분포를 시간에 따라 변화시켜 최종적으로 원하는 데이터로 샘플링되는 분포로 보내는 것을 목표로 함. 이것은 전에 부캠 프리코스에서 들었던 디퓨전 모델 구조와 유사하며, [DALL-E2 모델](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/)에서 이해했던 결과물과 유사한데, 현대 diffusion 모델의 근간이 아닐까 예상 중(지금 보니 아님 ㅋㅋ; SDE로 함)
- 다 읽고 나니 FFJORD의 학습 방법을 이해했다. 다만, FFJORD는 데이터셋의 분포를 역으로 보내서 어떤 분포를 찾고 그 분포 기반으로 학습하기는 하는데, 이건 내가 아는 diffusion과는 거리가 있다.
- FFJORD를 정리하자면,
    1. 우선 flow $f$가 주어지고, 데이터 $X$를 이 flow를 따라 역으로 보낸 Neural ODE를 계산한 원래 분포 $z(0)$를 계산
    2. 이를 바탕으로 loss값인 로그가능도를 최대화하는 방향으로 gradient descent를 진행(여기서 미분을 쉽게 하기 위해 Hutchinson estimator에 활용될 랜덤 보조 벡터를 사용한다)
- 이것은 데이터를 역으로 흘려 보낸 분포를 사용하는 것이지, gaussian에서 먼저 보낸 분포를 데이터와의 분포와 가깝게 한다는 개념과는 차이가 있어보인다. SDE 쪽을 내일 추가로 공부하면서 다시 생각해봐야겠다.

## Diffusion chapter 1:

### Stochastic Differential Equation

- Wiener process는 분산이 time difference가 되므로, Gaussian distribution에 sqrt of time diffrence를 곱한 것을 Wiener process로 보는 것은 당연하다.
- Intergration by parts: [product rule for divergence](https://en.wikipedia.org/wiki/Vector_calculus_identities#First_derivative_identities)  
Let $\varphi:\mathbb{R}^d\rightarrow\mathbb{R}^d$ and $f:\mathbb{R}^d\rightarrow\mathbb{R}$. Assume $\varphi$ and $f$ are sufficiently smooth and decay sufficiently quickly as $x\rightarrow\infty$. Then
\\(\int_{\mathbb{R}^d}\varphi(x)\cdot\nabla f(x) dx=-\int_{\mathbb{R}^d}\(\nabla\cdot\varphi\(x\)\)f\(x\)dx\\)

- SDE의 해….가 아니라 SDE의 해가 되는 distribution은 Fokker-Planck equation을 따른다
(해를 완전히 찾는 Joint distribution을 구하기 어려울 뿐더러, 각 해에 대한 marginal distribution만 구해도 충분하다)
- ODE는 앞뒤로 1대1 대응되므로, 그냥 수식을 음수로 쓰는 것 만으로 Reverse flow 연산을 구할 수 있다.
- **SDE는 그렇지 않다**. Wiener process등이 그대로 뒤집어지는 것이 아니며, 역으로 계산할 경우 Anderson’s theorem에 따른 추가적인 계산식이 필요하다. [왜?](https://medium.com/@hadarsharvit/diffusion-models-the-backward-process-of-removing-noise-part-2-846622d60769) 뒤에 빼주는 항도 가우시안 노이즈인데, 부호가 뒤집어져도 대칭이며, $g dW$ 항을 더해주는 것 자체가 forward 처럼 noise를 추가해주는 행위 자체와 동일하기 때문. Noise를 제거하는 것은 좀 더 다른 방향의 노력이 필요하다.
- 다만 Anderson 정리로 계산하려고 해도, 계산이 안되는 부분이 생긴다. 이 항을 score function이라고 하며, 다음 강의자료에서 학습한다. [구글링으로 찾은 글](https://junia3.github.io/blog/scoresde)도 추가로 읽어봐야겠다.
- Reverse SDE에서 얻어지는 marginal distribution과 동일한 분포를 가지는 Reverse ODE를 고려할 수 있다. 이를 활용하면 Reverse 생성 과정에서 추가되는 Z의 랜덤성을 없애면서도 생성값이 원래의 분포를 따르도록 할 수 있다. 다만 이 경우에도 score function이 발목을 잡는다. 
좀 찾아보니 [이 경우를 DDIM이라 하고 랜덤한 경우를 DDPM이라 하는 것](https://medium.com/@hadarsharvit/diffusion-models-the-backward-process-of-removing-noise-part-2-846622d60769)으로 일단 보이는데, 좀 더 공부해봐야할듯

## Diffusion Ch.2

Score matching에 대해서 학습하였다. Loss를 변형하는 방식에 따라 DSM과 SSM으로 나뉘며, 최종적으로는 둘 다 score function을 학습하는 네트워크를 구축하여 학습을 진행한다는 점을 이해했다.

또한 score function의 학습이 결과적으로 noise function의 학습과 유사하단 해석을 가지는 것도 직관에 도움이 되는 것 같다.
내일은 이렇게 score function이 학습된 이후 sampling을 SDE로 하는지 ODE로 하는지에 대해 짧게 알아보고 이번 주 diffusion 공부를 마무리할 것이다.

- 학습된 DSM score를 통해 SDE sampling을 실시하는 것을 DDPM sampling이라고 한다.
- 학습된 DSM score를 통해 ODE sampling을 하는 것을 DDIM sampling이라고 한다.
- ODE는 랜덤성이 없고 flow model로 해석할 수 있으며, 이를 통해 image interpolation 작업에 활용될 수 있다.
- FFJORD는 stochastisity가 없었는데, 이제야 좀 이해가 갈 것 같다. 시작점인 데이터셋 자체가 random variable이므로 random state에서 출발했다고 이해할 수 있다. 다만 그 움직이는 과정은 forward와 reverse 둘 다 deterministic한 ODE를 따라간다.
반면, forward SDE를 사용하면 random한 state가 random process를 따라간다. path에도 랜덤성이 생기는 것이다. 이 이후 reverse step에서 SDE를 활용하는지 ODE를 활용하는지에 따라 sampling 방법과 과정이 바뀌는 것으로 이해할 수 있다.

## Diffusion ch.3

### Score network

- Score network의 구성요소
    - [GELU](https://paperswithcode.com/method/gelu), [SiLU(swish)](https://paperswithcode.com/method/silu)
    - U-Net
    - Time embedding: trasnformer의 positional encoding과 유사하게
    - residual block: 1x1 conv를 지나는 residual connection이 있으며, time embedding은 scale-shift block에 scale과 shift로써 사용된다.
    - Pixel-wise multi-head self-attention:
        - single pixel with multi channel에 적용
        - ViT처럼 patch-wise로 적용하는 것이 아니며, conv layer와 섞어쓴다.
    - GroupNorm
        
        ![1](https://github.com/user-attachments/assets/6ae6f3ab-a009-4f1f-8f25-4acc69bbd86d)
        
- Score network structure
    - 내려가는 블록: downsampling, res block, res block, attn block
    - 올라가는 블록: concat, res block, res block, attn block, upsampling
    - 각 res block은 time embedding 값을 받아서 씀
- Tweedie’s formula: [읽을 것](https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html)
- Reverse conditional dist. $\approx$ Gaussian
    - Q. Why $p_X(x)=p_X(y)+\langle\nabla p_X(y), x-y\rangle +O(\|x-y\|^2)$?
    - Reverse conditional distribution이 Gaussian인 것을 유도하는 과정 자체에서도 reverse diffusion process의 additional drift term이 score fucntion이 됨을 [유도할 수 있다](https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html).
    - [Reverse Diffusion Process](https://www.notion.so/0cd41bccac244aacab4e73c496c817bc?pvs=21)

### DDPM

- 왜 DDPM의 분산은 ‘1-각 분산을 1에서 뺀 후 다 곱한것’ 이 되는 걸까
- DDPM loss 유도가 이해가 안된다. 원본 논문을 읽어봐야할듯
- DDPM에 나오는 모든 분산 값들의 유도 과정이 이해가 제대로 되지 않는다. 대략 $X_t=\sqrt{1-\sigma}X_{t-1}+\sigma Z$ 꼴 일때 계산이 되는 것 같긴 한데, 다음에 이 내용을 다시 공부한다면 이해할 수 있을까?
- DDPM은 forward 건 sampling이건 VP SDE의 이산화된 과정이 맞다. 어찌보면 DDPM에서 설정한 평균과 분산이 이를 노린 것으로 보이기도 한다.
- DDPM loss는 variational lower bound(VLB)를 통해서도 구할 수 있다.

### DDIM

- DDIM은 marginal distribution이 DDPM과 같아지도록 만든 non-makov process
- 따라서 학습 과정이 같다. sampling만 다르다
- $\rho_t$ 변수가 있는데, 0으로 설정하면 deterministic sampling이 가능하다.
- DDIM은 VP ODE의 이산화 과정이다. marginal이 같으므로 foward case는 DDPM과 증명이 동일. Sampling도 deterministic DDIM sampling은 Euler discretization of VP ODE이다.
- 어찌저찌 이해는 하겠다만 결국 conditional distribution의 분산을 유도하는 계산식이 이해가 잘 가지 않는다. 왜 $X_t\|X_{t-1}\sim\mathcal{N}(\sqrt{1-\beta_t}X_{t-1}, \beta_t I)$일 때 $X_t\|X_0$의 분산이 $(1-\prod_s (1-\beta_s))I$인 것인지.

## Diffusion ch.4

### Langevin MCMC

- MCMC는 따로 공부한 적이 있어서 이해할 수 있다. 친근한 분포의 sampling을 통해 적분하기 어려운 식의 적분값을 sample에 함숫값을 먹인 것의 평균으로 추정하는 것이다.
- Langevin MCMC라는 것은 뭘까. MCMC에 대한 설명을 적고 나니 이해할 것 같다.
- 일단 forward-reverse의 과정은 아니고, score fucntion+Wiener process term을 갖는 random process를 만들면 원래 distribution으로 수렴하게 된다.
$dX_t=\frac{1}{2}\nabla\log p(X_t)dt+dW_t$
- 이 때 score function을 학습시킨 뒤 MCMC 마냥 sampling해서 최종적으로는 데이터의 분포에서 sampling을 하고자하는 것이 목적인 것이다.

### Problem with Langevin MCMC

- 문제 1: [Support of distribution](https://en.wikipedia.org/wiki/Support_(mathematics))=확률이 0이 되는 가장 큰 열린 집합의 여집합. 즉 data distribution이 full suport가 안되서 꽉 채우지 못한다면(좀 차원이 낮다던지), 서포트 바깥에서의 $\log P(X)$ 값이 마이너스 무한대가 되서 계산이나 학습 자체가 불가능함. 즉 애초에 SSM을 적용해서 score function을 학습시킬 수 없음
- 그럼 로그값이 0이 되지 않도록 좀 perturb한 분포에 대해 DSM이나 SSM을 적용한다면? 그것도 안됨. 왜? 그건 문제 3에서
- 문제 2: 랑제빈 MCMC의 또다른 문제점으로는 수렴이 보장되지만 속도가 너무 느리다는 점이 있음. 따라서 급발진하는 **‘온도’ $\tau$**를 설정해준 후, 이 온도를 점점 낮춰줌
- Annealed langevin(천천히 식는 랑제빈): $dX_t=\frac{1}{2\tau}\nabla\log p(X_t)dt+dW_t$
    
    각 온도에서 sampling 이후, 마지막 sample을 다음 온도의 첫 sample로 사용
    
- 문제 3: 역시나 여전히 확률이 낮은 지점에선 score function 학습이 잘 안됨. 하지만 annealing 하는 과정에서 높은 온도에 있는 분포가 이 확률이 낮은 지점들을 찍고 다니는 경우가 생겨버림. 아니면 multimodal인 경우에 피크를 옮기는 과정에서 생기는 확률 낮은 점들을 찍는다던지
- 결국 해결책은? 아까 perturb noise를 크게 시작해서 점점 줄여나가고, 모든 noise에 대해 score fucntion을 학습시킨다→**Noise Conditioned Score Network(NCSN)**
- NCSN에선 $X~p_{\text{data}}$고 $\epsilon$이 정규분포인 경우에 다음과 같이 정의한다

\\(X+\sigma\epsilon\sim\tilde{p}^\sigma_{\text{data}}\\)

이 이후 학습은 DSM으로 하고 온도 annealing과 유사하게 진행

- 확률이 낮은 데이터가 높은 노이즈에선 score fucntion 학습이 잘 되는데 낮은 노이즈에선 잘 안될 수 있다. 이는 Annealed가 아닌 Langevin MCMC에서 제기된 문제기도 하다. 하지만 여기선 괜찮든데,
    - 애초에 낮은 온도에선 그 데이터 score가 잘 필요없고
    - conditional U-Net으로 학습된 score fucntion은 높은 노이즈 쪽에 데이터가 있고 낮은 노이즈 쪽에 데이터가 없다면 높은 노이즈와 낮은 노이즈의 score를 비슷하게 책정한다. 이는 타당한 추정치이다.
- 이런 문제가 Noise dependent인 NCSN이랑 다르게, time dependent인 Diffusion SDE나 DDPM에선 왜 안 일어난거지? 이런 네트워크에선 특정 시간 $t$에서 학습하면, 그 근방 시간도 같이 학습되기 때문. 합리적인 방향으로 계속 학습이 진행되므로, $t$가 작고 확률이 낮은 데이터여도 score function 학습이 잘 된다.
- NCSN은 VE SDE의 이산화이다. sampling에 대응되는 것은 아니고 score fucntion 학습할 때

### Conditional diffusion model

- 그냥 생성이 아니라 조건부 생성이 필요해진다.(text-to-image generation 모델이나 뒤에 나올 controllable generation model에서 중요하게 쓰이지 않을까?)
- 조건부 생성은 label $Y$(label이 아닐 수 있긴 하지만 일단은)가 주어졌을때 forward SDE, reverse SDE가 $\cdot\|Y$만 달고 똑같이 진행된다. 다만 결국 score function이 2개로 쪼개질 뿐.

\\(\nabla_{X_t}\log p_t(X_t\|Y) =\nabla_{X_t}\log p_t(X_t) + \nabla_{X_t}\log p_t(Y\|X_t)\\) 

- 그럼 어떻게 하냐?
    1. Y를 떼고 학습해서 통상적인 score fucntion $\nabla_{X_t}\log p_t(X_t)$ 학습을 진행(DSM 등)
    2. 오염된 데이터의 라벨을 예측하는, **시간에 의존하는 분류기 $c_\phi(X_t, Y, t)\approx p_t(Y\|X_t)$**를 따로 학습시킴. 지도학습 분류기랑 거의 비슷함(시간 붙는거 빼고)
    3. 위 2개를 합친 뒤 reverse-time conditional SDE로 샘플링
- 근데 해보니까 $\omega=1$을 쓰는 경우 50% 정도 일치율이 나오지만 눈으로 보기에 별로 결과가 안좋음. $\omega>>1$인 경우에 거의 100% 가깝게 나옴. 다양성과 재현율의 tradeoff→**Scaled classifier guidance**

\\(d\bar{X}_t=(f-g^2(\nabla_{X_t}\log p_t(X_t) + \omega\nabla_{X_t}\log p_t(Y\|X_t)))dt+gd\bar{W}_t, \bar{X}_T\sim p_T\\) with $\omega>1$

- 학습을 왜 2번 시켜야함? 분류기 없는 방법을 연구하자. 어차피 $x\|y$의 조건부 확률이 $y\|x$의 확률에 비례하니까

\\(d\bar{X}_t=(f-g^2((1-\omega)\nabla_{X_t}\log p_t(X_t) + \omega\nabla_{X_t}\log p_t(X_t\|Y)))dt+gd\bar{W}_t, \bar{X}_T\sim p_T\\) with classifier scale $\omega$

이렇게 쓰고 네트워크 하나로 score function 2개를 퉁치는 걸로→**Classifier-free guidance**

- 학습 과정에서 unconditioned 될 확률 20%로 잡고 unconditioned와 conditioned를 동시에 학습. 샘플링에선 앞의 항이 unconditioned score function, 뒤의 항이 conditioned score function.
- score function을 학습할 때, time embedding이 필요했던 것처럼 class embedding도 넣어줘야함. time embedding이랑 합쳐서 넣어줌

### Conditional diffusion application

1.  **image inpainting**. 여기선 forward model이 pixel-wise하게 적용한다고 가정하고, inpaint로 보내는 맵의 여집합 맵에 대한 조건부 확률을 이용하여 문제를 푼다. score function도 원래 구하던 방식에서 여집합 맵을 통해 계산하고, 이를 통해 여집합 샘플을 구해 전체 이미지를 복구
2. **Image colorization**. 그레이스케일에서 컬러이미지 복구하기. 사실 inpainting의 일종인데 orthogonal matrix를 먹이고 하는 것. orthogonal matrix에 의한 변환으로 score fucntion을 계산하기 편한 형태로 얻을 수 있다.
3. 이미지를 단 한 스텝의 diffusion으로 고해상도 이미지를 얻을 수 있을까? 계산 비용이 어마어마하다. **Cascade Diffusion Model(CDM)**에선 diffusion으로 저해상도 이미지를 만들고, 저해상도 이미지를 조건부확률로 갖는 diffusion을 통해 고해상도 이미지를 얻는다.
- 고해상도화 생성모델은 저해상도 이미지가 낳은 에러를 고해상도로 올리는 과정에서 에러를 키운다는 문제가 있다. CDM은 noise-corrupted된 img 를 조건부로 갖는 score fucntion을 학습시켜 이를 해결한다. sampling은 최종적으로 이 noise level을 하이퍼파라미터로 갖는다.
- Diffusion에 대해 전반적인 내용은 거의 다 알게 된 것 같아서 좋다. 마지막 내용도 그리 오래 걸릴 것 같진 않지만, 일단은 주말에 하는 쪽으로 해야할 듯

## Diffusion Ch.5

### GLIDE(Guided Language to Image Diffusion for generation and Editing)

- GLIDE with CLIP guidance
    - pretrained CLIP(Contrastive Language-Image Pre-training model)
    - Since $\log p(C\|X)\approx\frac{1}{\tau}f_\theta(X)\cdot g_\phi(C)+\text{constant independent of }X$, we can make use of this term as guiding score function.
    - But the problem is that $\log p(C\|X)\neq\log p(C\|X_t)$. So we pre-train time-dependent CLIP model.(trained separately from score network)
- GLIDE with Text-conditioning and classifier free guidance
    - In this case, we use classifier-free guidance, and uses a conditional error $\epsilon_\theta(X_t, t, C)$.
    - Here caption $C$ is embedded into a sequence of $K$ tokens and added to time embedding.
    - $K$ tokens are projected into key and value vectors of the attention layers of the U-Net, making cross-attention.

### DALL-E 2

- **DALL-E 2**는 Image Encoder $f_\theta$, Text encoder $g_\phi$, Image decoder $h_\psi$, Prior $p_\omega$로 이루어진 모델이다.
- **Stage 1**: CLIP encoders $f_\theta$ and $g_\phi$: 다른 네트워크 학습 중엔 얼려짐
    
![dall-e2](https://github.com/user-attachments/assets/c68238b4-ca66-4854-afcf-e764b948b99b)
    
- Decoder $h_\psi$는 conditional diffusion model로 학습되어 sample을 생성한다. 다음 3가지 경우가 있다.
    - $h_\psi(f_\theta(X), \emptyset)\approx X$는 의미론적 의미를 추출할 때 사용되어 $p(\cdot\|f_\theta(X))$에서 샘플을 만든다. ‘bipartite 표현식’에 멋지게 응용가능
    - $h_\psi(f_\theta(X), C)\approx X$는 $C$가 $X$를 잘 묘사한다면 더 정확한데, 최종 텍스트-to-이미지 생성 과정에 쓰인다. $p(\cdot\|f_\theta(X), C)$에서 추출됨
    - $h_\psi(0, \emptyset)\approx X$는 자막 $C$에 대응되는 이미지를 만드는데, 그리 잘 작동하지는 않지만 classifier-free guidance에서 쓰인다. $p(\cdot\|C)$에서 추출됨
- **Stage 2**: 다음 조건부 에러 네트워크를 학습한다.

\\(\epsilon_\psi(X_t, t, Z^\text{image}, C)\\)

- 이 때, $X_0=0, Z^\text{image}=f_\theta(X)$이고 $C$는 이미지 자막 순서쌍인 $(X,C)$로 주어진다.
- 10% 확률로 $Z^\text{image}=0$인 경우와 50%확률로 $C=\emptyset$인 경우를 학습한다.
- 이걸로 64x64 이미지를 만들고, CDM으로 해상도를 올린다.
- **Bipartite representation**: Image decoder에서 caption을 비우고, DDIM sampler로 $(X_T, Z^\text{image}$를 만든다. 뭔가 이상한 노이즈 같겠지만..DDIM을 뒤로 돌리면 다시 원래 이미지를 복구할 수 있다. 이 $(X_T, Z^\text{image})$ 페어를 bipartite representation이라 한다.
    - 응용 1-변형: X로 bipartite representation을 구하면, 이를 통해 $(X_0, Z^\text{image})$를 샘플링하여 $X$의 다양한 변형을 얻을 수 있다. 이미지 인코더와 캡션이 빈 이미지 디코더 사용
    - 응용 2-보간: 두 이미지 $X^{(1)}, X^{(2)}$에 대해, $Z=\eta f_\theta(X^{(1)})+(1-\eta)f_\theta(X^{(2)})$를 구해서 DDIM 샘플러를 돌리면 $\eta$에 따라 다양한 샘플을 얻을 수 있다.(단, $X_T\sim\mathcal{N}(0, I)$는 고정). 이미지 인코더와 빈캡션의 이미지 디코더 사용
    - 응용 3-텍스트로 변화주기: $(X, C, C^\text{new})$와 bipartite representation이 주어졌을 때, $Z=f_\theta(X)+\eta(g_\phi(C^\text{new})-g_\phi(C))$를 구성해서 DDIM 샘플러를 때리면 캡션 1에서 캡션 2의 형태로 변화하는 이미지 구성을 볼 수 있다. 이미지 인코더, 디코더, 텍스트 인코더를 전부 사용.
- prior 없이 텍스트를 이미지로 바꾸는 작업을 해보면 문제가 생긴다.
    1. $h_\phi(0, C)$로 생성하기: 결과가 구림
    2. $h_\phi(g_\phi(C), C)$로 생성하기: $h$는 이미지 임베딩으로 학습됐는데 강제로 텍스트 임베딩 $g$를 쓴 게 문제긴 하다. 결과는 좀 더 낫긴 하다
    3. prior $p_\omega$ 사용하기→최고의 결과를 얻음
- Prior $p_\omega$는 $p(Z^\text{image}\|Z^\text{text}, C)$로부터 샘플을 만든다. 수학적으로는 $Z^\text{text}=g_\phi(C)$라 필요 없는 조건이고 $p(X\|C)$로 충분해보이지만, 실전에선 CLIP-pretrained-feature인 $g_\phi(C)$가 필수인 것으로 드러났다.
- Prior를 어떻게 학습할 것인가?
    - auto-regressive model은 잘 작동하지 않는다.
    - Diffusion에 기반하여 학습시킨다. 이 때 순수 transformer 모델을 사용한다. 애초에 latent variable은 이미지가 아니라서 conv. layer가 도움이 안되기 때문.(실제로 그럼)
- 최종 DALL-E 2 생성 프로세스는 다음과 같다
    1. $Z^\text{text}=g_\phi(C)$ 계산
    2. latent variable인 $Z^\text{image}=p_\omega(Z^\text{text}, C)$ 생성
    3. 이걸로 원하는 이미지 $X$를 $h_\phi(Z^\text{image}, C)$에서 생성

### Imagen

- **Imagen**은 단순히 CDM인데, 사전 학습된 LLM으로 text imbedding을 함.
- Imagen 학습 프로세스
    1. T5(Text-To-Text Transfer Transformer)같은 LLM을 사전 학습시키고 얼림(이미지 안씀)
    2. 이미지-캡션 페어로 CDM 학습
    3. ‘Dynamic thresholding’ 기법을 통해 classifier-free guidance로 이미지 생성
- Classifier-free guidance에선 보통 큰 스케일 파라미터가 필요한데, 이러면 이미지 일치율이 구려지는 문제가 있음. 이미지가 포화되기 때문
- Dynamic thresholding을 간단히 설명하면, 이미지 픽셀 값을 잘라내지 않고 천천히 적정범위로 밀어넣는 테크닉임.
- 흥미롭게도, 에러 네크워크를 키우는 것보다 텍스트 인코더(여기서 LLM)을 키우는게 훨 중요하단 결과가 나옴

### Latent Diffusion Model

- 현재 Diffusion 모델의 문제점: 이미지에 직접 작용하기 때문에
    - 전체 이미지에 1000번 이상 스텝을 진행하는게 비효율적이고
    - 적용 범위가 좁아진다. 텍스트엔 어캐 할건데?
- 여기서 나온게 Variational autoencoder에 diffusion을 하는 것

![latent_diffusion](https://github.com/user-attachments/assets/85ba6d68-b172-4bc9-9525-cc104c2ecf7d)

- VLB 항을 3개로 쪼갤 수 있다: 순서대로 reconstruction term, negative encoder entropy, cross-entorpy

\\(
\text{VLB}\_{\phi, \theta, \psi}(X)=\mathbb{E}\_{Z\_0\sim q_\phi(\cdot\|X)} [-\log p_\psi(X\|Z_0)]+D_\text{KL}(q_\phi(\cdot\|X)\||p_\theta(\cdot))\\\ 
=\mathbb{E}\_{Z\_0 \sim q\_\phi(\cdot\|X)} [-\log p_\psi(X\|Z_0)]+\mathbb{E}\_{Z_0\sim q_\phi(\cdot\|X)} [\log q_\phi(Z_0\|X)]+\mathbb{E}\_{Z_0\sim q_\phi(\cdot\|X)} [-\log p_\theta(Z_0)]
\\)

- 일반적인 VAE에선 $q_\phi(\cdot\|X)=\mathcal{N}(\mu_\phi(X), \Sigma_\phi(X))$와 $p_\psi(\cdot\|Z_0)=\mathcal{N}(f_\psi(Z), \sigma^2 I)$니까, 앞의 두 항은 샘플링과 재매개변수화 트릭, 백프롭 등으로 쉽게 계산 가능하다.
- 마지막 항은 score matching으로 해결한다.

\\(
\text{CE}(q_\phi(\cdot\|X)\||p_\theta(\cdot)=\underset{t\sim\mathcal{U}[0,1]}{\mathbb{E}}\left[\frac{w(t)}{2}\underset{\substack{Z_0\sim q_\phi(\cdot\|X)\\\ \epsilon\sim\mathcal{N}(0, T)\\\ Z_t=\mu_t(Z_0)+\sigma_t\epsilon}}{\mathbb{E}}[\||\epsilon-\epsilon_\theta(Z_t, t)\||^2]\right]+\frac{d_Z}{2}\log(2\pi e \sigma_0)\\)

where $\mu_t(Z_0)$ is the mean of $Z_t$ conditioned on $Z_0$ under the SDE $dZ_t=f(t)Z_t dt+g(t)dW_t$

- Latent diffusion model의 최종 학습 과정:
    1. prior $p_z=\mathcal{N}(0,I)$ 하에서 VAE $(q_\phi, p_\psi)$를 사전학습
    2. 처음부터 끝까지 diffusion model과 VAE 전체 $(q_\phi, p_\psi, p_\theta)$를 학습시킨다. VAE를 고정시켜도 되지만, 같이 학습하는게 결과가 더 좋더라
- VAE가 가우시안 prior에서 사전학습되므로 디퓨전의 최종 마지널 분포도 가우시안이다. 이 상태에서 SDE를 VP-SDE가 되도록 고르면,  $p_\theta$의 학습이 일반적인 경우보다 훨씬 쉬워진다.
- 또한 일반적인 Diffusion에선 $X_0,X_1$이 엄청 다르지만, latent diffusion에선 $Z_0,Z_1$의 분포가 거의 비슷하다.

### Stable Diffusion

- **Stable Diffusion**: Autoencoder를 사전학습시키고 얼린 다음 Latent Diffusion model을 사용한 것. 그 이후 latent variable에 대한 conditional diffusion model을 만든다.
- 이후 수많은 혁신을 낳게 된다.
