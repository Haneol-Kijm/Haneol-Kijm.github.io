---
title: 부캠 3주차 일일 후기
layout: post
---



- 블로그 intro
- 블로그 Works 탭(포폴)
- ~~[ChatGPT](https://www.assemblyai.com/blog/how-chatgpt-actually-works/)와 [RLHF](https://www.assemblyai.com/blog/how-rlhf-preference-model-tuning-works-and-how-things-may-go-wrong/) 블로그 글~~
- ~~1주일에 코테 문제 1개~~
- ~~Diffusion Note~~
- [GNN 소개](https://distill.pub/2021/gnn-intro/)
- https://www.assemblyai.com/blog/an-introduction-to-poisson-flow-generative-models/
- https://www.assemblyai.com/blog/recent-developments-in-generative-ai-for-audio/
- [GraphSage](https://arxiv.org/abs/1706.02216?ref=assemblyai.com)


## 토요일

- 블로그 SNS 아이콘 정리작업
- 코테 1문제(스택/큐)

### [How RLHF Works](https://www.assemblyai.com/blog/how-rlhf-preference-model-tuning-works-and-how-things-may-go-wrong/)

[How RLHF Works 후기](https://www.notion.so/How-RLHF-Works-d3a162c62bf945afadd1fa8c79205396?pvs=21)

## 일요일

### [How ChatGPT Works](https://www.assemblyai.com/blog/how-chatgpt-actually-works/)

[How ChatGPT Works 후기](https://www.notion.so/How-ChatGPT-Works-7f8afcf8b16a42859a58682b688f06e5?pvs=21)

### [GNN 소개](https://distill.pub/2021/gnn-intro/)(Intro만 읽음)

이 글에서 하려고 하는 것 4가지

1. 어떤 데이터가 그래프로 표현되는지? 예시
2. 이게 다른 데이터랑 어떤 차별점이 있어서 쓰는건지?
3. 현대 GNN 모델 찬찬히 뜯어보기, 역사적으로 어떤 모티브로 나온건지
4. 독자가 직접 갖고 놀 수 있는 GNN 놀이터. 여기서 직관을 얻어가길

블로그에 등장하는 대부분의 figure가 interactive하게 짜여있는 것 자체가 좀 신기하고 놀랍다. 글을 읽고 이해함에 있어서 여러모로 신경 쓴 게 돋보인다.

## 11일차

### 데일리 트렌드

- [DeepSeekProverV1.5](https://huggingface.co/papers/2408.08152)에서는 수학적 언어 모델 위에 SFT와 RL을 적용시키려는 노력을 하는 것으로 보인다. 특히 RLPAF(Proof assistant feedback)은 휴먼 피드백에 대한 의존 없이 강화학습을 하려는 노력으로 보이는데, 흥미롭게 보여서 읽어보고 싶단 생각이 든다
- 대단히 nice한 [AI 프로그래밍](https://x.com/yacineMTB/status/1825033947333468363) 툴을 찾았다. 이런 걸 함부로 써도 되는 걸까? 안 쓰는 사람이 바보라곤 하는데..일단 현재 직장 일을 하는 것은 아니니 쓸 필요는 없어보인다.
- 멘토님께서 공유해주신 [SAMBA 논문](https://arxiv.org/pdf/2406.07522v1) abstrct도 흥미롭다. 무한한 길이의 sequence를 입력으로 받을 수 있다? LLM이 이런 길이가 긴 인풋과 아웃풋에 대해 한계점이 있는 걸로 아는데, recurrent하게 이런 부분을 해결할 수 있는지 궁금하다.

### 개인 공부

[Diffusion 공부](https://ernestryu.com/courses/FM.html) 계획

- 총 43, 34,25,41,46,38쪽 6챕. 하루 2챕을 뺄 수 있는지 시도해보고 진도를 결정

Diffusion chapter 0:

- Residual neural net의 층을 time index로 연속적으로 보면 상미분 방정식으로 해석할 수 있다는 게 놀라울 따름. 또한 비슷하게 chain rule을 써서 backprop의 해를 항상 구할 수 있다는 것이 보장됨
- 이를 뉴럴 네트워크로 해석하려면 gradient의 계산이 필요한데, input에 대한 미분값은 구할 수 있으나 parameter에 대한 미분값을 구하기가 어려움. 따라서 parameter도 시간에 따라 변하는 것으로 조작하여 문제를 해결함. Neural ODE는 이에 따라, ODE solver를 2번 호출하는 것으로 항상 계산할 수 있음
- Flow model이란 IID Gaussian 분포를 어떤 invertible한 함수를 통해 보낸 값으로 데이터를 샘플링하고 생성하는 생성형 모델임.
- Flow model에 위의 Neural ODE를 결합하여, FFJORD(Free-Form Jacobian Of Reversible Dynamics) 모델을 만들 수 있음. 이 모델은 가우시안 분포를 시간에 따라 변화시켜 최종적으로 원하는 데이터로 샘플링되는 분포로 보내는 것을 목표로 함. 이것은 전에 부캠 프리코스에서 들었던 디퓨전 모델 구조와 유사하며, [DALL-E2 모델](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/)에서 이해했던 결과물과 유사한데, 현대 diffusion 모델의 근간이 아닐까 예상 중
- 다 읽고 나니 FFJORD의 학습 방법을 이해했다. 다만, FFJORD는 데이터셋의 분포를 역으로 보내서 어떤 분포를 찾고 그 분포 기반으로 학습하기는 하는데, 이건 내가 아는 diffusion과는 거리가 있다.
- FFJORD를 정리하자면,
    1. 우선 flow f가 주어지고, 데이터 X를 이 flow를 따라 역으로 보낸 Neural ODE를 계산한 원래 분포 z(0)를 계산
    2. 이를 바탕으로 loss값인 로그가능도를 최대화하는 방향으로 gradient descent를 진행(여기서 미분을 쉽게 하기 위해 Hutchinson estimator에 활용될 랜덤 보조 벡터를 사용한다)
- 이것은 데이터를 역으로 흘려 보낸 분포를 사용하는 것이지, gaussian에서 먼저 보낸 분포를 데이터와의 분포와 가깝게 한다는 개념과는 차이가 있어보인다. SDE 쪽을 내일 추가로 공부하면서 다시 생각해봐야겠다.

## 12일차

### 데일리 트렌드

- [최신 LLM 논문](https://huggingface.co/papers/2408.08872)을 읽어보던 도중, 최근 LLM들은 PPO의 약점을 극복하기 위해 [DPO](https://velog.io/@mmodestaa/%ED%95%98%EB%82%98%EC%9D%98-%EC%96%B8%EC%96%B4%EB%AA%A8%EB%8D%B8%EC%9D%84-%EB%B3%B4%EC%83%81-%EB%AA%A8%EB%8D%B8%EB%A1%9C%EB%8F%84-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-DPO-Direct-Preference-Optimization%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C)를 대신 사용한다는 사실을 알게 되었다. PPO에서 보상모델을 학습하는 과정 없이 바로 Finetuning을 해주는 모양이다.

### 개인 학습

- 씻으면서 생각해봤고 이후 다시 확인해봤는데, FFJORD와 diffusion 모델 둘 다 flow model에 근간을 두고 있다. flow model이란 쉬운 분포 z를 데이터의 분포 x로 접근시키는 parametric flow $ h_\{theta}(z) $ 를 학습시켜 랜덤한 노이즈로 원래 데이터와 유사한 데이터를 생성하는 것이 목적인 모델이다. FFJORD는 여기서 $h_theta$로 neural ODE를 사용한 것이고, diffusion model은 랜덤성을 추가하는 SDE를 사용한 것이 큰 차이점이다.(논문에서도 neural SDE라고 언급한다)
다만 Diffusion에서는 접근을 달리하여, Z를 X로 보내는 것이 아니라, X에 SDE flow로 noise를 추가하여 Z로 보내는 식의 접근 방법을 취하고 있다. 그리고 학습 방법이 논문마다 차이가 있는 것으로 보여, 우선은 이 정도로만 정리하고 각 이론을 마저 학습한 뒤에 다시 정리하는 과정이 필요하다.

Diffusion chapter 1:

- Wiener process는 분산이 time difference가 되므로, Gaussian distribution에 sqrt of time diffrence를 곱한 것을 Wiener process로 보는 것은 당연하다.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac84168d-557f-4919-b37f-2632c6456077/297ad288-d3a2-4859-b77d-f2cfab4af12e/image.png)

- Intergration by parts: [product rule for divergence](https://en.wikipedia.org/wiki/Vector_calculus_identities#First_derivative_identities)
- SDE의 해….가 아니라 SDE의 해가 되는 distribution은 Fokker-Planck equation을 따른다
(해를 완전히 찾는 Joint distribution을 구하기 어려울 뿐더러, 각 해에 대한 marginal distribution만 구해도 충분하다)
- ODE는 앞뒤로 1대1 대응되므로, 그냥 수식을 음수로 쓰는 것 만으로 Reverse flow 연산을 구할 수 있다.
- **SDE는 그렇지 않다**. Wiener process등이 그대로 뒤집어지는 것이 아니며, 역으로 계산할 경우 Anderson’s theorem에 따른 추가적인 계산식이 필요하다. 왜?
- 다만 Anderson 정리로 계산하려고 해도, 계산이 안되는 부분이 생긴다. 이 항을 score function이라고 하며, 다음 강의자료에서 학습한다.
- Reverse SDE에서 얻어지는 marginal distribution과 동일한 분포를 가지는 Reverse ODE를 고려할 수 있다. 이를 활용하면 Reverse 생성 과정에서 추가되는 Z의 랜덤성을 없애면서도 생성값이 원래의 분포를 따르도록 할 수 있다. 다만 이 경우에도 score function이 발목을 잡는다.
- [Anderson 정리에 대해 추가로 읽어본 글](https://ludwigwinkler.github.io/blog/ReverseTimeAnderson/)
