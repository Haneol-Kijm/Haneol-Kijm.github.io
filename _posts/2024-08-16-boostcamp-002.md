---
title: 부캠 2주차 일일 후기
layout: post
hidden: true
---


#### Table of Contents
1. [6일차](#6일차)
2. [7일차](#7일차)
3. [8일차](#8일차)
4. [9일차](#9일차)
5. [10일차](#10일차)
6. [2주차 후기](#2주차-후기)



## 6일차:

### 부캠 강의

- sigmoid와 softmax 함수의 차이점을 정리하는 계기가 되어 좋았음

### 개인 학습

지난 번 LLM article의 연장선상에 있는 article들을 몇 개 읽어보았다.

- https://research.google/blog/pathways-language-model-palm-scaling-to-540-billion-parameters-for-breakthrough-performance/?ref=changelog.assemblyai.com
PaLM(Pathway Language Model)의 돌파 성능에 대해 이것저것 소개하고 있으며, 그 측면들은 나름 놀라운 면이 있으나, 왜 그런 돌파 성능이 생기는 지는 구체적으로 설명하고 있지 않아서 짧게 읽고 넘어갔다.
- https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/#references
에서는 LLM의 발현된 능력이 왜 나타났는지, 그리고 어떻게 활용해야할지를 두고 쉽고 재밌게 소개하고 있다.
    - LLM의 발현 능력은 큰 파라미터 스케일에서 나타나는 특수 태스크 능력인데, 이를 두고 2가지 해석이 존재한다
        - 흥미로운 해석으로는 특수 태스크가 간단한 사고 능력의 연쇄여서, 이 연쇄가 만약 10개가 있다고 한다면 10단계를 전부 잘 수행할 수 있을 정도로 파라미터가 늘어나서 특수 태스크를 수행할 수 있는 것이라고 설명한다.
        - 조금 식는 해석으로는 특수 태스크의 성능을 측정하는 metric 자체가 잘못되어있으며, 공을 맞출지 말지로 해석하는 것이 아닌, 공을 얼마나 가깝게 던졌는지로 메트릭을 조정하면 실제로 발현된 것처럼 보이는게 아니라 점진적으로 성능이 좋아지는 것을 확인할 수 있다.
    - 이런 발현 능력 현상을 두고 궁극적으로는 어떻게 활용할 것이냐? 그럼 모델을 무식하게 크게 만들면 되지 않는가? 라는 질문에는 그에 상응하도록 데이터셋을 무식하게 늘려야해서 현재 불가능하다라는 답변으로 마무리한다.
    - 주요 레퍼런스(2개)
        - https://arxiv.org/abs/2206.04615?ref=assemblyai.com
        - https://arxiv.org/pdf/2206.07682
- https://www.assemblyai.com/blog/how-chatgpt-actually-works/
    
    ChatGPT에 대해 설명하고 있으나, 요약이 어려워 RLHF 설명을 읽고 다시 읽어봐야 할 것 같다.
    
- 그 외 앞으로 읽어보고 싶은 것
    
    [https://www.assemblyai.com/blog/an-introduction-to-poisson-flow-generative-models/](https://www.assemblyai.com/blog/an-introduction-to-poisson-flow-generative-models/)
    
    [https://www.assemblyai.com/blog/recent-developments-in-generative-ai-for-audio/](https://www.assemblyai.com/blog/recent-developments-in-generative-ai-for-audio/)
    
     [GraphSage](https://arxiv.org/abs/1706.02216?ref=assemblyai.com)
    
    [https://www.assemblyai.com/blog/how-rlhf-preference-model-tuning-works-and-how-things-may-go-wrong/](https://www.assemblyai.com/blog/how-rlhf-preference-model-tuning-works-and-how-things-may-go-wrong/)
    

## 7일차

### 부캠강의

- computational graph의 chain rule에 대해서 항상 헷갈리던 부분이 있었는데, upstream*local grad = downstream으로 나눠서 이해하니 쉽게 이해하게 되었다.
- ReLU를 많이 쓰는 이유가 궁금했었는데 sigmoid와 tanh activation의 단점들을 명확하게 이해할 수 있어 좋았다.
- **PCA 복습할것(내일이라도)**
- backpropagation을 직접 구현하는 것이 이토록 어려운 일이었는가? 세네시간의 고민 끝에 식을 전부 유도하는 데에 성공했다.

### 개인 학습

오늘은 진행하지 않았음

### 피어 세션-github study

- tracked 된 파일은 commit과 add가 동시에 가능하다는 걸 깨달았다.
- revert와 reset의 차이에 대해 이해했다. revert는 1단계씩만 해야한다는 것도
- 3주차-1 26페이지까지 완료(merge)

## 8일차

### 부캠강의

- chain rule을 직접 손으로 유도해봐야 정확한 계산식이 나온다는 점을 깨달았다. 행렬간의 chain rule은 물론 수학적으로 단순히 표현되는 것은 가능하지만, 정확히 계산하려면 결국 summation 꼴로 나타나기 때문에 직접 유도를 하는 편이 좋다.
- 과제2의 계산식을 전부 끝마쳤으나, mini-batch sgd에서 평균을 언제 취하는지에 대한 궁금증이 있었다….
- 는 [bias의 derivative](https://datascience.stackexchange.com/questions/20139/gradients-for-bias-terms-in-backpropagation)에 대한 이해가 부족해서 생긴 일
bias는 $x1 = x*W1+b$ 의 꼴로 더해지는 것처럼 보이나, 실은 행렬이 아니라 벡터 형태이며, 앞의 계산식과 맞춰주기 위해 각 batch sample들에 대해 broadcasting 연산으로 더해진다. 즉,
$x1 = x*W1+(b1|b1|…|b1)$ 
꼴의 연산인 것이다. 이를 기반으로 미분을 유도하면,

```python
db1 = np.ones(batch_size)@dx1
```

- attention을 수식으로만 이해하고 있었는데, 어떤 contextualization한 의미, seq2seq model로부터 연상된 의미에 대해 이해할 수 있어서 좋았다.

### 멘토링 클래스

- 논문 읽는 법, 탑티어 논문 학회, 트렌드 따라잡기 등에 대해 들었는데 공감이 가고 이러한 부분에 부족함이 있음을 느낀다
- 코딩 테스트도 꾸준히 준비하고 문제를 풀면 좋은데, 요즘 소홀했다는 생각이 든다
- 멘토님의 소중한 트렌드 따라잡기 팁
    
    Computer Vision Task 관련 정보 찾을 수 있는 링크
    
    - https://www.v7labs.com/blog/what-is-computer-vision
    - https://paperswithcode.com/area/computer-vision
    
    AI Conference Deadlines
    
    - https://aideadlin.es/?sub=CV
    
    컴퓨터 비전 전반적인 모델에 대한 분석 글 (조금은 옛날 정보 / 흐름에 대해서만 확인하는 정도로 활용!)https://kmhana.tistory.com/3최신 트렌드를 팔로우 하는 방법
    
    - 유튜브, 트위터, 페이스북, Paperswithcode, Reddit, Blog
    - 트위터 https://twitter.com/_akhaliq?lang=en
    - Paperswithcode : https://paperswithcode.com/
    - Hugging face 등? : https://huggingface.co/papers
    - 카카오톡 오픈챗 (인공지능 키워드)

### 피어 세션

- 처음으로 주도적으로 미적분 문제풀이하는 시간을 가져보았는데, 준비도 미흡했고 다른 분들 시간을 날린 것 같아 죄송한 마음이 들었다. 다음부터는 사람들의 수요를 조사하고 진행해야겠다.

### 마스터 클래스

## 9일차(광복절)

### 블로그 작업

광복절로 수업은 쉬었으나 블로그 테마 및 글 정리를 위해 오후 내내 카페에서 작업하였다.

- 기존 블로그 ‘WhatATheme’ 테마가 제대로 동작하지 않아 ‘Bay’ theme으로 바꾸었음
- ‘Bay’도 일부 동작하지 않는 부분이 있어 ruby와 jekyll을 직접 설치하였으나, 사실은 홈페이지의 url을 수정하는 것으로 제대로 동작하는 것으로 확인
- 블로그에 링크를 첨부하기 위해+최근 논문 트렌드를 확인하기 좋다고 하여 hugging face와 twitter에 가입하고 linkedin과 카카오톡의 ID를 검색하기 쉽도록 변경하였다

## 10일차:

### 트렌드 구경

오늘부터 매일 아침 10~15분 씩 투자하여 트위터를 구경하고 논문 한 편의 abstract 정도를 읽는 시간을 가져보기로 했다

- 트위터에서 발견한 유용한 읽을 거리: [GNN 소개](https://distill.pub/2021/gnn-intro/)
- Diffusion 모델의 문제점으로 생성된 이미지의 랜덤성이 조명되고 있다. 이를 통제하려는 노력들이 여럿 있으나, 통제에 리소스를 너무 잡아먹고, 이 통제마저도 제대로 안되는 경우가 허다하다. 이를 극복하는 모델과 방법론을 제시하는 [논문](https://huggingface.co/papers/2408.06070)이다.
이 논문 흐름을 보아하니 diffusion에 대해 좀 더 자세히 공부할 필요성이 느껴진다.

### 부캠 강의

- 과제 2, 3 제출을 완료하였다
- 심화과제가 keras로 되어있어서 전부 pytorch로 구현해보았다.
    - patch를 만들 땐 nn.unfold를 유용하게 활용할 수 있다.
    - 이미지를 plot하고 싶다면 기본이 3*size*size 형태이므로, reshape나 view가 아니라 permute(1, 2, 0)을 적용해야만 올바른 그림이 나온다.
    - torch.repeat_interleave는 numpy.repeat와 유사하며, torch.repeat와 다르다.

### 개인 학습

논문을 자세히 보진 못하고, 블로그 정리 및 주간 회고를 마무리 하였다.

## 2주차 후기

- 좋았던 점:
    - 아침 트위터 구경을 추가하여 하루 루틴을 깔끔하게 정리한 점이 마음에 든다
    - 블로그를 드디어 깔끔하게 정리해서 기분이 좋다
- 아쉬운 점:
    - 과제에 얽매여서 논문 리뷰나 이력서를 아예 건드려보지 못한 점이 마음에 걸린다.
    - 점점 수업 내용이 심화되면서 개인 공부 시간이 슬금슬금 줄어드는 영향을 느끼는데, 과제 시간 투자를 최소화하는 편으로 연습하는 편이 좋을 것 같다.
- 도전할 점: 시간 관계상 주말을 활용해서 추가로 진행하고 싶다
    - 블로그 꾸미기에 성공했으니, 블로그를 포트폴리오처럼 다듬으면서 기존 내용들을 재정리하는 시간을 가지고 싶다.
    - PCA 내용 정리하기
    - ChatGPT와 RLHF 블로그 글 확인하기
    - 1주일에 코테 문제 1개씩 풀기(아마 주말?)
- 알게된 점:
    - 생각보다 torch autograd의 편리함을 너무 누리고 있었단 생각이 든다. 미분을 직접 계산하는 것은 상당히 복잡한 일이었다.
    - 트위터, 허깅페이스, paperswithcode, linkedin 등 사람들은 생각보다 커뮤니티를 되게 많이 활용해서 소통을 하고 정보를 공유하고 있었다. 매일 짧은 시간을 투자해서라도 잠깐잠깐 확인할 필요성을 느꼈다.
