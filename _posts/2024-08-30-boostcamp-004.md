---
title: 부스트캠프 4주차 후기
layout: post
draft: true
use_math: true
---
<details>
<summary>TODO</summary>
    
- 블로그 intro
- 블로그 Works 탭(포폴)
- 공부의 족적 정리(PCA 내용 정리하기)→ 차원감소법 정리하기
- latex 문법 정리하기
- **Diffusion Note**
- [GNN 소개](https://distill.pub/2021/gnn-intro/)
- [GNN의 convolution에 대해](https://distill.pub/2021/understanding-gnns/)
- https://www.assemblyai.com/blog/an-introduction-to-poisson-flow-generative-models/
- https://www.assemblyai.com/blog/recent-developments-in-generative-ai-for-audio/
- [GraphSage](https://arxiv.org/abs/1706.02216?ref=assemblyai.com)
- Mamba
- [VLM을 소개하는 페이퍼](https://huggingface.co/papers/2408.12637)
</details>


## 토요일

- 드디어 github pages에서 mathjax를 이용해서 완전히 latex 수식을 구현하는 것에 성공
    - $$ 기호를 못알아먹어서 \\( 기호로 표기함
    - \newline 명령어도 안 들어먹던데 \*3번 쓰는 걸로 라인브레이크를 만듦
    - 행렬에서도 똑같이 triple slash로 되긴 하는데, 엔터를 치면 안됨. 하..ㅋㅋ;
    - 또 다른 이슈…[]그냥 브래킷을 씌우면 인식이 안되서 \[\] 식으로 꼭 써줘야함
    - 마크다운의 더블 언더바(__)도 이탤릭 처리와 헷갈려서, 언더바가 많이 등장하는 경우에 \_ 식으로 처리해줘야 알아먹음. $$ 기호를 \\( 기호로 바꾼 것의 스노우볼 같은데, 수식 인식이 아니라 마크다운 인식을 거친 후에 수식으로 바뀌는 식이라 마크다운 양식과 충돌이 너무 많다
- CS231A 과제1을 주로 하는데 수업이 수업이라 그런지 난이도가 상당한 느낌. 다행히 2,3번은 아직 배우지 않은 내용이라 스킵하고 과제0 파이썬과 선대 연습 쪽 과제를 해야겠다.

## 일요일

- CS231A 과제0 완료. ndarray.shape 호출할 때 pair가 호출되므로 shape[0] 식으로 불러야 함에 주의(소괄호인줄 알았음;)
- 또한 [np.dot](http://np.dot) 사용할 때, 모양을 직접 맞춰서 곱해줘야 하므로 np.dot(a.T, b) 형식으로 곱해줘야함.
- (3,) 꼴의 벡터를 (3,1)로 만드려고 np.expand_dims(a, axis=-1)을 쓰긴 했는데…다른 좋은 방법이 없을까?

Diffusion ch.3

- Score network의 구성요소
    - [GELU](https://paperswithcode.com/method/gelu), [SiLU(swish)](https://paperswithcode.com/method/silu)
    - U-Net
    - Time embedding: trasnformer의 positional encoding과 유사하게
    - residual block: 1x1 conv를 지나는 residual connection이 있으며, time embedding은 scale-shift block에 scale과 shift로써 사용된다.
    - Pixel-wise multi-head self-attention:
        - single pixel with multi channel에 적용
        - ViT처럼 patch-wise로 적용하는 것이 아니며, conv layer와 섞어쓴다.
    - GroupNorm
        
        ![1](https://github.com/user-attachments/assets/6ae6f3ab-a009-4f1f-8f25-4acc69bbd86d)
        
- Score network structure
    - 내려가는 블록: downsampling, res block, res block, attn block
    - 올라가는 블록: concat, res block, res block, attn block, upsampling
    - 각 res block은 time embedding 값을 받아서 씀
- Tweedie’s formula: [읽을 것](https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html)
- Reverse conditional dist. $\approx$ Gaussian
    - Q. Why $p_X(x)=p_X(y)+\langle\nabla p_X(y), x-y\rangle +O(\|x-y\|^2)$?
    - Reverse conditional distribution이 Gaussian인 것을 유도하는 과정 자체에서도 reverse diffusion process의 additional drift term이 score fucntion이 됨을 [유도할 수 있다](https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html).
    - [Reverse Diffusion Process](https://www.notion.so/0cd41bccac244aacab4e73c496c817bc?pvs=21)

## 16일차

### 데일리 트렌드

- [LLM의 원리를 시각화 한 영상](https://x.com/Hamptonism/status/1827439848426500303). 고차원에 임베딩된 단어 벡터들은 방향 그 자체로 의미를 형상화한다는 내용이 있는데, 일리있고 신기하단 생각이 든다.
- LLM의 컨트롤을 아예 [서베이 페이퍼](https://huggingface.co/papers/2408.12599)로. 이 컨트롤 작업도 태스크가 내용 컨트롤과 특성 컨트롤 2가지로 나뉘는 모양이다. 시간만 된다면 꼭 읽어보고 싶은 논문
- [휴먼 비전 파운데이션 모델](https://huggingface.co/papers/2408.12569). 무슨 모델을 쓰나 봤더니 [Masked Autoencoder](https://arxiv.org/pdf/2111.06377)라는 생소한 모델을 쓰고 있었다.
    
    ![masked autoencoder](https://github.com/user-attachments/assets/fe89a996-b849-41d2-9bca-94472745e4f6)
    
    - 패치단위로 학습하는것까진 ViT, MLPMixer와 유사하다.
    - 그러나 빈 칸을 채우는 식으로 학습한다.
    - 이런 식으로 학습한 모델은 일반화도 잘되며, 다른 다운스트림 태스크도 잘 수행한다고 한다.

## 부캠 강의

- 극좌표계를 matplotlib으로 그려보는데, rmin을 세팅해도 도넛 모양이 되지는 않고 원 중심값이 min값이 되버린다…도넛은 matplotlib으로 그리기 번거로울 걸로 예상이 된다. 아마 동심원을 써서 도넛인 첫 해야할 듯.
- 역시 도넛은 예상대로 pie chart에 빈 원.

## 개인학습

Diffusion note Ch.3

- 왜 DDPM의 분산은 ‘1-각 분산을 1에서 뺀 후 다 곱한것’ 이 되는 걸까
- DDPM loss 유도가 이해가 안된다. 원본 논문을 읽어봐야할듯
- DDPM에 나오는 모든 분산 값들의 유도 과정이 이해가 제대로 되지 않는다. 대략 $X_t=\sqrt{1-\sigma}X_{t-1}+\sigma Z$ 꼴 일때 계산이 되는 것 같긴 한데, 다음에 이 내용을 다시 공부한다면 이해할 수 있을까?
- DDPM은 forward 건 sampling이건 VP SDE의 이산화된 과정이 맞다. 어찌보면 DDPM에서 설정한 평균과 분산이 이를 노린 것으로 보이기도 한다.
- DDPM loss는 variational lower bound(VLB)를 통해서도 구할 수 있다.
- DDIM은 marginal distribution이 DDPM과 같아지도록 만든 non-makov process
- 따라서 학습 과정이 같다. sampling만 다르다
- $\rho_t$ 변수가 있는데, 0으로 설정하면 deterministic sampling이 가능하다.
- DDIM은 VP ODE의 이산화 과정이다. marginal이 같으므로 foward case는 DDPM과 증명이 동일. Sampling도 deterministic DDIM sampling은 Euler discretization of VP ODE이다.
- 어찌저찌 이해는 하겠다만 결국 conditional distribution의 분산을 유도하는 계산식이 이해가 잘 가지 않는다. 왜 $X_t\|X_{t-1}\sim\mathcal{N}(\sqrt{1-\beta_t}X_{t-1}, \beta_t I)$일 때 $X_t\|X_0$의 분산이 $(1-\prod_s (1-\beta_s))I$인 것인지.

## 17일차

### 데일리 트렌드

- [VLM을 소개하는 페이퍼](https://huggingface.co/papers/2408.12637). 시간 날 때 읽어보고 싶다. 이번 수업에서도 다룬다고 하니 주말 이용해서 읽으면 좋아 보인다.

### Github 특강

### 개인 학습

CS231A

- Magnification이 줄면 barrel 현상, 늘면 pincushion 현상. 근데 **magnification이 뭐지?**
- [lecture 3 후기](https://haneol-kijm.github.io/2024/08/27/CS231A-003)

Diffusion ch.4

- MCMC는 따로 공부한 적이 있어서 이해할 수 있다. 친근한 분포의 sampling을 통해 적분하기 어려운 식의 적분값을 sample에 함숫값을 먹인 것의 평균으로 추정하는 것이다.
- Langevin MCMC라는 것은 뭘까. MCMC에 대한 설명을 적고 나니 이해할 것 같다.
- 일단 forward-reverse의 과정은 아니고, score fucntion+Wiener process term을 갖는 random process를 만들면 원래 distribution으로 수렴하게 된다.
$dX_t=\frac{1}{2}\nabla\log p(X_t)dt+dW_t$
- 이 때 score function을 학습시킨 뒤 MCMC 마냥 sampling해서 최종적으로는 데이터의 분포에서 sampling을 하고자하는 것이 목적인 것이다.
- 문제 1: [Support of distribution](https://en.wikipedia.org/wiki/Support_(mathematics))=확률이 0이 되는 가장 큰 열린 집합의 여집합. 즉 data distribution이 full suport가 안되서 꽉 채우지 못한다면(좀 차원이 낮다던지), 서포트 바깥에서의 $\log P(X)$ 값이 마이너스 무한대가 되서 계산이나 학습 자체가 불가능함. 즉 애초에 SSM을 적용해서 score function을 학습시킬 수 없음
- 그럼 로그값이 0이 되지 않도록 좀 perturb한 분포에 대해 DSM이나 SSM을 적용한다면? 그것도 안됨. 왜? 그건 문제 3에서
- 문제 2: 랑제빈 MCMC의 또다른 문제점으로는 수렴이 보장되지만 속도가 너무 느리다는 점이 있음. 따라서 급발진하는 **‘온도’ $\tau$**를 설정해준 후, 이 온도를 점점 낮춰줌
- Annealed langevin(천천히 식는 랑제빈): $dX_t=\frac{1}{2\tau}\nabla\log p(X_t)dt+dW_t$
    
    각 온도에서 sampling 이후, 마지막 sample을 다음 온도의 첫 sample로 사용
    
- 문제 3: 역시나 여전히 확률이 낮은 지점에선 score function 학습이 잘 안됨. 하지만 annealing 하는 과정에서 높은 온도에 있는 분포가 이 확률이 낮은 지점들을 찍고 다니는 경우가 생겨버림. 아니면 multimodal인 경우에 피크를 옮기는 과정에서 생기는 확률 낮은 점들을 찍는다던지
- 결국 해결책은? 아까 perturb noise를 크게 시작해서 점점 줄여나가고, 모든 noise에 대해 score fucntion을 학습시킨다→**Noise Conditioned Score Network(NCSN)**
- NCSN에선 $X~p_{\text{data}}$고 $\epsilon$이 정규분포인 경우에 다음과 같이 정의한다

\\(X+\sigma\epsilon\sim\tilde{p}^\sigma_{\text{data}}\\)

이 이후 학습은 DSM으로 하고 온도 annealing과 유사하게 진행

## 18일차

### 데일리 트렌드

- [총게임 AI를 트랜스포머를 활용해서 만듦](https://huggingface.co/papers/2408.13934). 트랜스포머는 계속해서 강력한 모델로 당분간 쓰일 건가 보다.
- [Pytorch는 죽었다 JAX 최고](https://news.hada.io/topic?id=16369): 아직까진 논란의 여지가 있어보이지만 tensorflow가 결국 pytorch에 먹힌 것처럼, jax에 대해서도 공부해두는 것 자체는 의미있어보인다. 다만 [다른 레딧 글](https://www.reddit.com/r/MachineLearning/comments/1b08qv6/d_is_it_worth_switching_to_jax_from/)을 참조해도 구글이 오픈소스 라이브러리를 유기한 경력이 많기 때문에 신뢰할 수 없다는 의견이 마찬가지로 보인다. 
jax의 장단점:
    - pytorch보다 코딩이 어렵다
    - pytorch보다 문서화가 덜 되어있다
    - 코딩 스타일 적응하려면 좀 시간이 걸린다
    - 그래도 jax로 새로 작업한 코드가 훨씬 빠르다
    - 일부 pytorch로 불가능한 필요한 기능들이 jax에 있는 경우에 전환할 만 하다.
- [실용적 코드 편집기](https://news.hada.io/topic?id=16400&utm_source=weekly&utm_medium=email&utm_campaign=202435): 댓글 봤는데 한글 표시 안된다고 해서 바로 취소
- [인간 vs 언어모델](https://news.hada.io/topic?id=16368&utm_source=weekly&utm_medium=email&utm_campaign=202435): 4/15점에 380초. LLM은 6/15점에 9초 걸린다고 한다. 확실히 AI는 인간이 수작업으로 할 수 없는 영역을 쉽고 간편하게 해주는 궁극의 도구가 맞는 것 같다…

## Github 특강

## 개인 학습

Diffusion ch.4(이어서)

- 확률이 낮은 데이터가 높은 노이즈에선 score fucntion 학습이 잘 되는데 낮은 노이즈에선 잘 안될 수 있다. 이는 Annealed가 아닌 Langevin MCMC에서 제기된 문제기도 하다. 하지만 여기선 괜찮든데,
    - 애초에 낮은 온도에선 그 데이터 score가 잘 필요없고
    - conditional U-Net으로 학습된 score fucntion은 높은 노이즈 쪽에 데이터가 있고 낮은 노이즈 쪽에 데이터가 없다면 높은 노이즈와 낮은 노이즈의 score를 비슷하게 책정한다. 이는 타당한 추정치이다.
- 이런 문제가 Noise dependent인 NCSN이랑 다르게, time dependent인 Diffusion SDE나 DDPM에선 왜 안 일어난거지? 이런 네트워크에선 특정 시간 $t$에서 학습하면, 그 근방 시간도 같이 학습되기 때문. 합리적인 방향으로 계속 학습이 진행되므로, $t$가 작고 확률이 낮은 데이터여도 score function 학습이 잘 된다.
- NCSN은 VE SDE의 이산화이다. sampling에 대응되는 것은 아니고 score fucntion 학습할 때
- 그냥 생성이 아니라 조건부 생성이 필요해진다.(text-to-image generation 모델이나 뒤에 나올 controllable generation model에서 중요하게 쓰이지 않을까?)
- 조건부 생성은 label Y(label이 아닐 수 있긴 하지만 일단은)가 주어졌을때 forward SDE, reverse SDE가 $\cdot\|Y$만 달고 똑같이 진행된다. 다만 결국 score function이 2개로 쪼개질 뿐.

\\(\nabla_{X_t}\log p_t(X_t\|Y) =\nabla_{X_t}\log p_t(X_t) + \nabla_{X_t}\log p_t(Y\|X_t)\\) 

- 그럼 어떻게 하냐?
    1. Y를 떼고 학습해서 통상적인 score fucntion $\nabla_{X_t}\log p_t(X_t)$ 학습을 진행(DSM 등)
    2. 오염된 데이터의 라벨을 예측하는, **시간에 의존하는 분류기 $c_\phi(X_t, Y, t)\approx p_t(Y\|X_t)$**를 따로 학습시킴. 지도학습 분류기랑 거의 비슷함(시간 붙는거 빼고)
    3. 위 2개를 합친 뒤 reverse-time conditional SDE로 샘플링
- 근데 해보니까 $\omega=1$을 쓰는 경우 50% 정도 일치율이 나오지만 눈으로 보기에 별로 결과가 안좋음. $\omega>>1$인 경우에 거의 100% 가깝게 나옴. 다양성과 재현율의 tradeoff→**Scaled classifier guidance**

\\(d\bar{X}_t=(f-g^2(\nabla_{X_t}\log p_t(X_t) + \omega\nabla_{X_t}\log p_t(Y\|X_t)))dt+gd\bar{W}_t, \bar{X}_T\sim p_T\\) with $\omega>1$

- 학습을 왜 2번 시켜야함? 분류기 없는 방법을 연구하자. 어차피 $x\|y$의 조건부 확률이 $y\|x$의 확률에 비례하니까

\\(d\bar{X}_t=(f-g^2((1-\omega)\nabla_{X_t}\log p_t(X_t) + \omega\nabla_{X_t}\log p_t(X_t\|Y)))dt+gd\bar{W}_t, \bar{X}_T\sim p_T\\) with classifier scale $\omega$

이렇게 쓰고 네트워크 하나로 score function 2개를 퉁치는 걸로→**Classifier-free guidance**

- 학습 과정에서 unconditioned 될 확률 20%로 잡고 unconditioned와 conditioned를 동시에 학습. 샘플링에선 앞의 항이 unconditioned score function, 뒤의 항이 conditioned score function.
- score function을 학습할 때, time embedding이 필요했던 것처럼 class embedding도 넣어줘야함. time embedding이랑 합쳐서 넣어줌
- SDE diffusion application 1: **image inpainting**. 여기선 forward model이 pixel-wise하게 적용한다고 가정하고, inpaint로 보내는 맵의 여집합 맵에 대한 조건부 확률을 이용하여 문제를 푼다. score function도 원래 구하던 방식에서 여집합 맵을 통해 계산하고, 이를 통해 여집합 샘플을 구해 전체 이미지를 복구
- application 2: **Image colorization**. 그레이스케일에서 컬러이미지 복구하기. 사실 inpainting의 일종인데 orthogonal matrix를 먹이고 하는 것. orthogonal matrix에 의한 변환으로 score fucntion을 계산하기 편한 형태로 얻을 수 있다.
- application 3: 이미지를 단 한 스텝의 diffusion으로 고해상도 이미지를 얻을 수 있을까? 계산 비용이 어마어마하다. **Cascade Diffusion Model(CDM)**에선 diffusion으로 저해상도 이미지를 만들고, 저해상도 이미지를 조건부확률로 갖는 diffusion을 통해 고해상도 이미지를 얻는다.
- 고해상도화 생성모델은 저해상도 이미지가 낳은 에러를 고해상도로 올리는 과정에서 에러를 키운다는 문제가 있다. CDM은 noise-corrupted된 img 를 조건부로 갖는 score fucntion을 학습시켜 이를 해결한다. sampling은 최종적으로 이 noise level을 하이퍼파라미터로 갖는다.
- Diffusion에 대해 전반적인 내용은 거의 다 알게 된 것 같아서 좋다. 마지막 내용도 그리 오래 걸릴 것 같진 않지만, 일단은 주말에 하는 쪽으로 해야할 듯

CS231A

- [Lecture 4 후기](https://www.notion.so/Lecture-4-Single-View-Metrology-4d0cde1c76464355b5e24f7556fd0091?pvs=21)
- 내용이 생각보다 많이 수학적이어서 혼자 공부하는 사람들이 꽤 난감할 수도 있겠다는 생각이 든다. 내일 Lecture 5를 확실히 마무리하고 과제도 빨리 시작하는 쪽으로 해야할 듯

## 19일차

### 데일리 트렌드

- [구글 제미니](https://x.com/CodeByPoonam/status/1828471294322712745)가 이것저것 기능을 더 넣은 모양이다. 무료로 더 쓸 수 있는 건 장점인듯?
- diffusion model에 layout control을 넣는 시도는 많았지만, [3D layout control](https://x.com/_akhaliq/status/1828626760902070576)은 좀 귀한가보다. 계산속도가 빠른지 좀 궁금하긴 한데 빠르겠지?
- [Diffusion으로 게임엔진을 만들었다는 흥미로운 논문](https://x.com/_akhaliq/status/1828631472632172911). 3초밖에 기억을 못하긴 하지만, 노이즈 증강을 통해 이런것도 가능하다는 것 자체가 신기하다. 어쩌면 Diffusion 생성모델은 궁극의 생성을 낳을 수 있는 게 아닌가?
- [Writing in the Margins](https://github.com/writer/writing-in-the-margins): 추천수가 어마어마하게 많은 논문. ‘마진’은 중간 정보를 뜻하는 것 같고, KV cache라는 걸 이용해서(key-value?) 긴 문맥의 내용을 복구할 수 있게 해준다고 한다. 추가적인 fine-tune이 필요 없고, 끝에 계산량을 살짝 늘리는 것만으로 성능을 좋게 해주며, 최종 사용자에게 필요한 정보들을 처리할 수 있다는 점에서 점수가 높은게 아닌가 싶다.

### 부캠 강의

- 과제가 친절해서 좋다
  
### 멘토링

- 수업 시간에 가볍게 넘길만한 내용을 생각을 깊게 해볼 계기를 주고, 생각하는 방법을 알려주셔서 정말 유익한 시간을 보냈다.
- 추가 꿀팁으로 회사 다닐때 필요한 역량도 소개해주셔서 취직에 큰 도움이 될 것 같다.

### 개인 학습

CS231A Lecture 5

- [review](https://www.notion.so/Lecture-5-Epipolar-Geometry-4f2792856906471992af21867be7ff69?pvs=21)

## 20일차

### 데일리 트렌드

- 메타의 Llama 3.1 버전이 1달전 공개됐는데, 3억 5천만 다운로드를 돌파
- NVIDIA의 [EAGLE](https://x.com/FuxiaoL/status/1829296519305998738). Multimodal LLM에 대해서 vision encoder의 다양한 조합을 실험하고, 이를 통해 hallucination 등을 극복할 수 있다고 한다.

### 부캠 강의

- 의미에서 이미지를 만드는 것은 computer graphics, 이미지에서 이미지를 만드는 것은 image processing, 이미지에서 의미를 추출하는 것이 computer vision이라는 3분법을 배웠는데, 좋은 개념 정리라고 본다.
- Vision model의 역사를 배우면서 Swin transformer, MAE, DINO등을 새로 접했다. 내겐 아직 기초적인 역사 공부가 부족한게 아닌가 생각이 든다.

### 개인 학습

[CS231A 과제1 마무리](https://haneol-kijm.github.io/2024/08/24/CS231A-ps1)

## 4주차 후기

- 좋았던 점:
    - 부트캠프 강좌+개인 공부(디퓨전)+CS231 스터디 3종으로 1주일을 빡빡하게 사용했다.
    - 특히 스터디는 하루 3시간 씩 투자하여 github와 github page 기록을 알차게 채울 수 있었다.
    - Diffusion 공부를 이번 주에 거의 마무리하게 되어 기분이 좋다.
    - 아침 일찍 일어나 운동하기에 성공했다.
- 아쉬운 점:
    - **이력서 다듬기**는 다음주부터 Diffusion 공부 시간이 빠지므로 개인 학습 시간을 활용해서 진행하고 싶다.
- 도전할 점: 시간 관계상 주말을 활용해서 추가로 진행하고 싶다
    - 부캠 345강 강의 주말에 미리 듣기
    - 1주일에 코테 문제 1개씩 풀기
    - Diffusion note 마무리하기
- 알게된 점:
    - 부캠 수업을 통해 Diffusion model과 ViT 사이의 모델들에 대한 공부나 개념이 부족한 걸 알게 되었다. 추가 공부가 필요하지 않을까 싶다.
